\section{Appetizer: Using Probability to Cover a Set}

A \underline{convex combination} of points $z_1, \dots, z_m \in \mathbb{R}^n$ is a linear combination with coefficients 
that are nonnegative and sum to 1, i.e. it is a sum of the form
\[ \sum_{i = 1}^{m} \lambda_i z_i, \quad \lambda_i \geq 0 \text{  and  } \sum_{i = 1}^{m} \lambda_i = 1. \]

The \underline{convex hull} of a set $T \in \mathbb{R}^n$ is the set of all convex combinations of all finite 
collections of points in $T$, i.e. 
\[ \text{conv}(T) := \{\text{convex combinations of } z_1, \dots, z_m \in T \text{ for } m \in \mathbb{N}\}. \]

\begin{theorem}[\textbf{Caratheodory Theorem}]
\label{thm:0.0.1}
Every point in the convex hull of a set $T \subseteq \mathbb{R}^n$ can be expressed as a convex combination of at most 
$n + 1$ points from $T$.
\end{theorem}
\begin{proof}
Denote the point as 
\[ p = a_1 x_1 + \cdots + a_m x_m, \ a_i \geq 0, \ \sum_{i = 1}^{m} a_i = 0. \]
There are two cases that we can consider: 

\textbf{Case 1: $m \leq n + 1$}. Then $p$ is already in the desired form and we don't need to worry about it.

\textbf{Case 2: $m > n + 1$}. Then the set of $n - 1$ points $\{x_2 - x_1, \dots, x_m - 1\}$ have to be linearly 
dependent because we have at least $n + 1$ points in a subspace of $\mathbb{R}^n$. Let $b_2, \dots, b_m \in \mathbb{R}$ 
be not all zero such that 
\[ \sum_{i = 2}^{m} b_i (x_i - x_1) = 0. \]
From the above, by adding an extra term when $i = 1$, there exists $n$ numbers $c_1, \dots, c_n$ such that 
\[ \sum_{i = 1}^{m} c_i x_i = 0 \text{  and  } \sum_{i = 1}^{m} c_i = 0. \]
Define $I = \{i \in \{1, 2, \dots, n\}: c_i > 0\}$. The set is nonempty by the results that we have above. Define 
\[ \alpha = \max_{i \in I} a_i / c_i. \]
Then we can rewrite our point $p$ as 
\[ p = p - 0 = \sum_{i = 1}^{m} a_i x_i - \alpha \sum_{i = 1}^{m} c_i x_i = \sum_{i = 1}^{m} (a_i - \alpha c_i)x_i, \]
which is a convex combination with at least one zero coefficient, meaning $p$ can be written as a convex combination 
of $m - 1$ points in $T$ (we can check this!). By continuing to apply the above, we can eventually arrive 
at the case when $p$ consists of a combination of exactly $n + 1$ points, as desired.
\end{proof}

\begin{theorem}[\textbf{Approximate Caratheodory Theorem}]
\label{thm:0.0.2}
Consider a set $T \subseteq \mathbb{R}^n$ that is contained in the unit Euclidean ball. Then, for every point 
$x \in \text{conv}(T)$ and every $k \in \mathbb{N}$, one can find points $x_1, \dots, x_k \in T$ such that 
\[ \bigg\| x - \frac{1}{k} \sum_{j = 1}^{k} x_j \bigg\|_2 \leq \frac{1}{\sqrt{k}}. \]
\end{theorem}

\begin{proof}
We'll apply a technique called the \textit{empirical method}. Fix $x \in \text{conv}(T)$ so 
\[ x = \lambda_1 z_1 + \cdots + \lambda_m z_m, \ \lambda_i \geq 0, \ \sum_{i = 1}^{m} \lambda_i = 1. \]
From the above, we can consider the $\lambda_i$'s as weights to a probability distribution. Define the random 
vector $Z$ with its pmf being 
\[ P(Z = z_i) = \lambda_i, \ i = 1, 2, \dots, m. \]
We can immediately get that the expected value of $Z$ is 
\[ \mathbb{E}[Z] = \sum_{i = 1}^{m} z_i P(Z = z_i) = \sum_{i = 1}^{m} \lambda_i z_i = x. \]
Now consider $Z_1, \cdots, Z_k$ with the same distribution as $Z$. The strong law of large numbers tells us that 
\[ \frac{1}{k}\sum_{j = 1}^{k} Z_j \to x \text{  almost surely as  } k \to \infty. \]
For a more quantitative result, consider the mean-squared error:
\[ \mathbb{E}\biggl[ \bigg\| x - \frac{1}{k}\sum_{j = 1}^{k}Z_j \bigg\|_2^2 \biggr] 
= \frac{1}{k^2} \mathbb{E}\biggl[ \bigg\| \sum_{j = 1}^{k} (Z_j - x) \bigg\|_2^2 \biggr] 
= \frac{1}{k^2} \sum_{j = 1}^{k} \mathbb{E}[\| Z_j - x \|_2^2], \]
where the third equality is proved in exercise 3. For each term in the summation, 
\begin{align*}
	\mathbb{E}[\|Z_j - x\|_2^2] 
	&= \mathbb{E}[\|Z - \mathbb{E}[Z]\|_2^2] \\
	&= \mathbb{E}[\|Z\|_2^2] - \|\mathbb{E}[Z]\|_2^2 \quad (\text{Exercise 1}) \\
	&\leq \mathbb{E}[\|Z\|_2^2] \\
	&\leq 1. \quad (\text{Since } Z \in T).
\end{align*}
Then, we get that 
\[ \mathbb{E}\biggl[ \bigg\| x - \frac{1}{k}\sum_{j = 1}^{k}Z_j \bigg\|_2^2 \biggr] \leq \frac{1}{k}. \]
Therefore, there exists a realization $Z_1, \dots, Z_k$ such that 
\[ \bigg\| x - \frac{1}{k}\sum_{j = 1}^{k}Z_j \bigg\|_2^2 \leq \frac{1}{k}. \]
\end{proof}


% ----------0.0.1----------
\subsection{Covering Geometric Sets}
Caratheodory theorem has some applications, namely in covering sets: To cover a given set $P \subset 
\mathbb{R}^n$ with balls of a given radius, how many balls are required to cover $P$? The Approximate 
Caratheodory theorem can help us in these kinds of situations: 

\begin{corollary}[Covering polytopes by balls]
\label{cor:0.1.1}
Let $P$ be a polytope in $\mathbb{R}^n$ with $N$ vertices, contained in the unit Euclidean ball. Then 
for every $k \in \mathbb{N}$, the polytope $P$ can be covered by at most $N^k$ Euclidean balls of radii $
1 / \sqrt{k}$.
\end{corollary}

\begin{proof}
Consider the set 
\[ \mathcal{N} := \left\{ \frac{1}{k}\sum_{j = 1}^{k} x_j: \ x_j 
\text{ are vertices of } P \right\}. \]
We claim that the family of balls centered at points in $\mathcal{N}$ cover the set $P$. To check this, we 
can see that $P \subset \text{conv}(P) \subset \text{conv}(T)$ where $T = \{\text{Vertices of } P\}$. 
Then we apply \cref{thm:0.0.2} to any point $x \in P \subseteq \text{conv}(T)$ and deduce that $x$ is within 
distance $1/\sqrt{k}$ from some point in $\mathcal{N}$. This shows that the balls with radii $1/\sqrt{k}$ 
centered at $\mathcal{N}$ indeed cover $P$. 

To bound $|\mathcal{N}|$, there are $N^k$ ways to choose $k$ out of $N$ vertices with replacement, and 
we are done.	
\end{proof}

Covering is useful in, for example, computing the volume of a general polyhedron (which is not easy in 
high dimensions). Here is a simple bound: 
\begin{theorem}[]
\label{thm:0.1.2}
Let $P$ be a polytope with $N$ vertices, which is contained in the unit Euclidean ball of $\mathbb{R}^n$, 
denoted by $B$. Then 
\[ \frac{\text{Vol}(P)}{\text{Vol}(B)} \leq \left( 3 \sqrt{\frac{\log{N}}{n}} \right)^n. \]
\end{theorem}

\begin{proof}
\cref{cor:0.1.1} says that the polytope $P$ can be covered by at most $N^k$ balls of radius $1/\sqrt{k}$. 
The volume of each ball is $(1/\sqrt{k})^{n} \text{Vol}(B)$ because we are in dimension $n$. The volume of 
$P$ is bounded by the total volume of the balls that cover $P$, hence 
\[ \text{Vol}(p) \leq N^k (1 / \sqrt{k})^n \text{Vol}(B). \]
Rearranging the terms above gives 
\[ \frac{\text{Vol}(P)}{\text{Vol}(B)} \leq \frac{N^k}{k^{n/2}}. \]
This is true for every $k \in \mathbb{N}$. We can find the optimal $k$ by differentiating and setting 
to 0. Then we get 
\[ k_0 = \frac{n}{2 \log{N}}, \]
but we need $k$ to be an integer! Hence we take $k = \lfloor k_0 \rfloor$. Since $k_0 \leq k \leq k_0 + 1$, 
then plugging in the bound we get 
\[ \frac{\text{Vol}(P)}{\text{Vol}(B)} \leq \frac{N^{k_0 + 1}}{k_0^{n / 2}} 
\leq N \left( \sqrt{\frac{2e \log{N}}{n}} \right)^n. \]
Now there are two cases: If $N \leq e^{n / 9}$, then plugging in this bound gives that the RHS is bounded 
by $(3 \sqrt{\log{N} / n})^n$ hence the proof is complete. If $N > e^{n / 9}$, then the RHS is greater than 
equal to 1 hence the bound trivially holds (Vol($P$) $\leq$ Vol($B$)).
\end{proof}

\begin{remark}[A high-dimensional surprise]
\cref{thm:0.1.2} gives the counterintuitive conclusion: Polytopes with a modest number of vertices have 
extremely small volume! We can interpret the corollary above as "The polytope $P$ has volume as small 
as the Euclidean balls of radius $3 \sqrt{\log{N} / n}$, and maybe smaller".
\end{remark}

As being mentioned, there will be many other high-dimensional phenomena that are mentioned later in the book.
